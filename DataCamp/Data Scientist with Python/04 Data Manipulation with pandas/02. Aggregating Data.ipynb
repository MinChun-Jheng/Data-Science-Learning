{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "sales = pd.read_csv(\"sales_subset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0  store type  department        date  weekly_sales  is_holiday  \\\n",
      "0           0      1    A           1  2010-02-05      24924.50       False   \n",
      "1           1      1    A           1  2010-03-05      21827.90       False   \n",
      "2           2      1    A           1  2010-04-02      57258.43       False   \n",
      "3           3      1    A           1  2010-05-07      17413.94       False   \n",
      "4           4      1    A           1  2010-06-04      17558.09       False   \n",
      "\n",
      "   temperature_c  fuel_price_usd_per_l  unemployment  \n",
      "0       5.727778              0.679451         8.106  \n",
      "1       8.055556              0.693452         8.106  \n",
      "2      16.816667              0.718284         7.808  \n",
      "3      22.527778              0.748928         7.808  \n",
      "4      27.050000              0.714586         7.808  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10774 entries, 0 to 10773\n",
      "Data columns (total 10 columns):\n",
      "Unnamed: 0              10774 non-null int64\n",
      "store                   10774 non-null int64\n",
      "type                    10774 non-null object\n",
      "department              10774 non-null int64\n",
      "date                    10774 non-null object\n",
      "weekly_sales            10774 non-null float64\n",
      "is_holiday              10774 non-null bool\n",
      "temperature_c           10774 non-null float64\n",
      "fuel_price_usd_per_l    10774 non-null float64\n",
      "unemployment            10774 non-null float64\n",
      "dtypes: bool(1), float64(4), int64(3), object(2)\n",
      "memory usage: 768.1+ KB\n",
      "None\n",
      "23843.950148505668\n",
      "12049.064999999999\n"
     ]
    }
   ],
   "source": [
    "# 1. Print the head of the sales DataFrame\n",
    "print(sales.head())\n",
    "\n",
    "# Print the info about the sales DataFrame\n",
    "print(sales.info())\n",
    "\n",
    "# Print the mean of weekly_sales\n",
    "print(sales[\"weekly_sales\"].mean())\n",
    "\n",
    "# Print the median of weekly_sales\n",
    "print(sales[\"weekly_sales\"].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2012-10-26\n",
      "2010-02-05\n"
     ]
    }
   ],
   "source": [
    "# 2. Summarizing dates\n",
    "# Print the maximum of the date column\n",
    "print(sales[\"date\"].max())\n",
    "\n",
    "# Print the minimum of the date column\n",
    "print(sales[\"date\"].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        temperature_c  fuel_price_usd_per_l  unemployment\n",
      "iqr         16.583333              0.073176         0.565\n",
      "median      16.966667              0.743381         8.099\n"
     ]
    }
   ],
   "source": [
    "# 3. Import NumPy and create custom IQR function\n",
    "# use DF.agg(function)\n",
    "import numpy as np\n",
    "def iqr(column):\n",
    "    return column.quantile(0.75) - column.quantile(0.25)\n",
    "\n",
    "# Update to print IQR and median of temperature_c, fuel_price_usd_per_l, & unemployment\n",
    "print(sales[[\"temperature_c\", \"fuel_price_usd_per_l\", \"unemployment\"]].agg([iqr, np.median]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             date  weekly_sales  cum_weekly_sales  cum_max_sales\n",
      "0      2010-02-05      24924.50      2.492450e+04       24924.50\n",
      "6437   2010-02-05      38597.52      6.352202e+04       38597.52\n",
      "1249   2010-02-05       3840.21      6.736223e+04       38597.52\n",
      "6449   2010-02-05      17590.59      8.495282e+04       38597.52\n",
      "6461   2010-02-05       4929.87      8.988269e+04       38597.52\n",
      "6473   2010-02-05      20578.79      1.104615e+05       38597.52\n",
      "6485   2010-02-05       3953.70      1.144152e+05       38597.52\n",
      "1237   2010-02-05       6916.00      1.213312e+05       38597.52\n",
      "6425   2010-02-05       5089.54      1.264207e+05       38597.52\n",
      "6506   2010-02-05       6261.35      1.326821e+05       38597.52\n",
      "1225   2010-02-05      10322.43      1.430045e+05       38597.52\n",
      "6530   2010-02-05      12478.00      1.554825e+05       38597.52\n",
      "6542   2010-02-05      25160.36      1.806429e+05       38597.52\n",
      "6566   2010-02-05      10577.70      1.912206e+05       38597.52\n",
      "1213   2010-02-05       1592.41      1.928130e+05       38597.52\n",
      "6578   2010-02-05       7043.39      1.998564e+05       38597.52\n",
      "6590   2010-02-05       3303.98      2.031603e+05       38597.52\n",
      "6518   2010-02-05       7638.42      2.107988e+05       38597.52\n",
      "6602   2010-02-05       1232.07      2.120308e+05       38597.52\n",
      "6413   2010-02-05      21710.43      2.337413e+05       38597.52\n",
      "6401   2010-02-05      24525.54      2.582668e+05       38597.52\n",
      "1309   2010-02-05        975.50      2.592423e+05       38597.52\n",
      "6237   2010-02-05     213042.66      4.722850e+05      213042.66\n",
      "6258   2010-02-05      45017.96      5.173029e+05      213042.66\n",
      "6270   2010-02-05      24273.74      5.415767e+05      213042.66\n",
      "1297   2010-02-05       4216.00      5.457927e+05      213042.66\n",
      "6293   2010-02-05      21500.58      5.672932e+05      213042.66\n",
      "6305   2010-02-05      52144.50      6.194377e+05      213042.66\n",
      "1261   2010-02-05      17212.26      6.366500e+05      213042.66\n",
      "6317   2010-02-05      18215.03      6.548650e+05      213042.66\n",
      "...           ...           ...               ...            ...\n",
      "3591   2012-07-13          0.07      2.568869e+08      293966.05\n",
      "9007   2012-07-13          0.06      2.568869e+08      293966.05\n",
      "8071   2012-07-20         80.96      2.568870e+08      293966.05\n",
      "1594   2012-07-27          6.00      2.568870e+08      293966.05\n",
      "5016   2012-08-10        -98.00      2.568869e+08      293966.05\n",
      "6256   2012-08-10          6.39      2.568869e+08      293966.05\n",
      "7905   2012-08-17       -175.00      2.568867e+08      293966.05\n",
      "7725   2012-08-24        -34.00      2.568867e+08      293966.05\n",
      "8630   2012-08-24          0.00      2.568867e+08      293966.05\n",
      "6734   2012-08-31          4.47      2.568867e+08      293966.05\n",
      "10568  2012-08-31         14.96      2.568867e+08      293966.05\n",
      "8072   2012-09-07         -8.97      2.568867e+08      293966.05\n",
      "6735   2012-09-07         13.41      2.568867e+08      293966.05\n",
      "3223   2012-09-21        389.00      2.568871e+08      293966.05\n",
      "525    2012-09-28        224.00      2.568873e+08      293966.05\n",
      "8073   2012-10-05         18.89      2.568874e+08      293966.05\n",
      "2698   2012-10-05        490.00      2.568878e+08      293966.05\n",
      "900    2012-10-05        635.00      2.568885e+08      293966.05\n",
      "7198   2012-10-05        870.00      2.568894e+08      293966.05\n",
      "6816   2012-10-05        448.00      2.568898e+08      293966.05\n",
      "6736   2012-10-05         13.41      2.568898e+08      293966.05\n",
      "9008   2012-10-05        435.00      2.568902e+08      293966.05\n",
      "6292   2012-10-05        750.00      2.568910e+08      293966.05\n",
      "5407   2012-10-05       1130.00      2.568921e+08      293966.05\n",
      "1797   2012-10-05        595.00      2.568927e+08      293966.05\n",
      "3592   2012-10-05        440.00      2.568932e+08      293966.05\n",
      "8108   2012-10-05        660.00      2.568938e+08      293966.05\n",
      "10773  2012-10-05        915.00      2.568947e+08      293966.05\n",
      "6257   2012-10-12          3.00      2.568947e+08      293966.05\n",
      "3384   2012-10-26        -21.63      2.568947e+08      293966.05\n",
      "\n",
      "[10774 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "# 4. Cumulative statistics\n",
    "# introduct Cumulative\n",
    "# df.sort_value(\"data\",)\n",
    "# df.cumsum(), .cummax(), .cummin(), cumprod()\n",
    "# Sort sales_1_1 by date\n",
    "sales_1_1 = sales\n",
    "sales_1_1 = sales_1_1.sort_values(\"date\")\n",
    "\n",
    "# Get the cumulative sum of weekly_sales, add as cum_weekly_sales col\n",
    "sales_1_1[\"cum_weekly_sales\"] = sales_1_1[\"weekly_sales\"].cumsum()\n",
    "\n",
    "# Get the cumulative max of weekly_sales, add as cum_max_sales col\n",
    "sales_1_1[\"cum_max_sales\"] = sales_1_1[\"weekly_sales\"].cummax()\n",
    "\n",
    "# See the columns you calculated\n",
    "print(sales_1_1[[\"date\", \"weekly_sales\", \"cum_weekly_sales\", \"cum_max_sales\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Counting\n",
    "1. DataFrame.drop_duplicates(subset=None, keep='first', inplace=False, ignore_index=False)\n",
    "Return DataFrame with duplicate rows removed.\n",
    "2. DataFrame.value_counts(subset=None, normalize=False, sort=True, ascending=False)\n",
    "Return a Series containing counts of unique rows in the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Unnamed: 0  store type  department        date  weekly_sales  \\\n",
      "0              0      1    A           1  2010-02-05      24924.50   \n",
      "901          901      2    A           1  2010-02-05      35034.06   \n",
      "1798        1798      4    A           1  2010-02-05      38724.42   \n",
      "2699        2699      6    A           1  2010-02-05      25619.00   \n",
      "3593        3593     10    B           1  2010-02-05      40212.84   \n",
      "\n",
      "      is_holiday  temperature_c  fuel_price_usd_per_l  unemployment  \n",
      "0          False       5.727778              0.679451         8.106  \n",
      "901        False       4.550000              0.679451         8.324  \n",
      "1798       False       6.533333              0.686319         8.623  \n",
      "2699       False       4.683333              0.679451         7.259  \n",
      "3593       False      12.411111              0.782478         9.765  \n",
      "    Unnamed: 0  store type  department        date  weekly_sales  is_holiday  \\\n",
      "0            0      1    A           1  2010-02-05      24924.50       False   \n",
      "12          12      1    A           2  2010-02-05      50605.27       False   \n",
      "24          24      1    A           3  2010-02-05      13740.12       False   \n",
      "36          36      1    A           4  2010-02-05      39954.04       False   \n",
      "48          48      1    A           5  2010-02-05      32229.38       False   \n",
      "\n",
      "    temperature_c  fuel_price_usd_per_l  unemployment  \n",
      "0        5.727778              0.679451         8.106  \n",
      "12       5.727778              0.679451         8.106  \n",
      "24       5.727778              0.679451         8.106  \n",
      "36       5.727778              0.679451         8.106  \n",
      "48       5.727778              0.679451         8.106  \n",
      "      Unnamed: 0  store type  department        date  weekly_sales  \\\n",
      "498          498      1    A          45  2010-09-10         11.47   \n",
      "691          691      1    A          77  2011-11-25       1431.00   \n",
      "2315        2315      4    A          47  2010-02-12        498.00   \n",
      "6735        6735     19    A          39  2012-09-07         13.41   \n",
      "6810        6810     19    A          47  2010-12-31       -449.00   \n",
      "6815        6815     19    A          47  2012-02-10         15.00   \n",
      "6820        6820     19    A          48  2011-09-09        197.00   \n",
      "\n",
      "      is_holiday  temperature_c  fuel_price_usd_per_l  unemployment  \n",
      "498         True      25.938889              0.677602         7.787  \n",
      "691         True      15.633333              0.854861         7.866  \n",
      "2315        True      -1.755556              0.679715         8.623  \n",
      "6735        True      22.333333              1.076766         8.193  \n",
      "6810        True      -1.861111              0.881278         8.067  \n",
      "6815        True       0.338889              1.010723         7.943  \n",
      "6820        True      20.155556              1.038197         7.806  \n"
     ]
    }
   ],
   "source": [
    "# 5. Dropping duplicates\n",
    "# Drop duplicate store/type combinations\n",
    "store_types = sales.drop_duplicates(subset=[\"store\", \"type\"])\n",
    "print(store_types.head())\n",
    "\n",
    "# Drop duplicate store/department combinations\n",
    "store_depts = sales.drop_duplicates(subset=[\"store\", \"department\"])\n",
    "print(store_depts.head())\n",
    "\n",
    "# Subset the rows where is_holiday is True and drop duplicate dates\n",
    "holiday_dates = sales[sales[\"is_holiday\"]].drop_duplicates(subset=['date'])\n",
    "\n",
    "# Print date col of holiday_dates\n",
    "print(holiday_dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A    11\n",
      "B     1\n",
      "Name: type, dtype: int64\n",
      "A    0.916667\n",
      "B    0.083333\n",
      "Name: type, dtype: float64\n",
      "41    12\n",
      "30    12\n",
      "23    12\n",
      "24    12\n",
      "25    12\n",
      "26    12\n",
      "27    12\n",
      "28    12\n",
      "29    12\n",
      "31    12\n",
      "21    12\n",
      "32    12\n",
      "33    12\n",
      "34    12\n",
      "35    12\n",
      "36    12\n",
      "38    12\n",
      "40    12\n",
      "22    12\n",
      "20    12\n",
      "42    12\n",
      "9     12\n",
      "2     12\n",
      "3     12\n",
      "4     12\n",
      "5     12\n",
      "6     12\n",
      "7     12\n",
      "8     12\n",
      "10    12\n",
      "      ..\n",
      "82    12\n",
      "83    12\n",
      "85    12\n",
      "87    12\n",
      "90    12\n",
      "91    12\n",
      "67    12\n",
      "60    12\n",
      "59    12\n",
      "58    12\n",
      "56    12\n",
      "55    12\n",
      "54    12\n",
      "52    12\n",
      "51    12\n",
      "94    12\n",
      "49    12\n",
      "95    12\n",
      "47    12\n",
      "46    12\n",
      "96    12\n",
      "45    12\n",
      "97    12\n",
      "92    12\n",
      "99    11\n",
      "37    10\n",
      "48     8\n",
      "50     6\n",
      "39     4\n",
      "43     2\n",
      "Name: department, Length: 80, dtype: int64\n",
      "41    0.012917\n",
      "30    0.012917\n",
      "23    0.012917\n",
      "24    0.012917\n",
      "25    0.012917\n",
      "26    0.012917\n",
      "27    0.012917\n",
      "28    0.012917\n",
      "29    0.012917\n",
      "31    0.012917\n",
      "21    0.012917\n",
      "32    0.012917\n",
      "33    0.012917\n",
      "34    0.012917\n",
      "35    0.012917\n",
      "36    0.012917\n",
      "38    0.012917\n",
      "40    0.012917\n",
      "22    0.012917\n",
      "20    0.012917\n",
      "42    0.012917\n",
      "9     0.012917\n",
      "2     0.012917\n",
      "3     0.012917\n",
      "4     0.012917\n",
      "5     0.012917\n",
      "6     0.012917\n",
      "7     0.012917\n",
      "8     0.012917\n",
      "10    0.012917\n",
      "        ...   \n",
      "82    0.012917\n",
      "83    0.012917\n",
      "85    0.012917\n",
      "87    0.012917\n",
      "90    0.012917\n",
      "91    0.012917\n",
      "67    0.012917\n",
      "60    0.012917\n",
      "59    0.012917\n",
      "58    0.012917\n",
      "56    0.012917\n",
      "55    0.012917\n",
      "54    0.012917\n",
      "52    0.012917\n",
      "51    0.012917\n",
      "94    0.012917\n",
      "49    0.012917\n",
      "95    0.012917\n",
      "47    0.012917\n",
      "46    0.012917\n",
      "96    0.012917\n",
      "45    0.012917\n",
      "97    0.012917\n",
      "92    0.012917\n",
      "99    0.011841\n",
      "37    0.010764\n",
      "48    0.008611\n",
      "50    0.006459\n",
      "39    0.004306\n",
      "43    0.002153\n",
      "Name: department, Length: 80, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# 6. Counting categorical variables\n",
    "# Count the number of stores of each type\n",
    "store_counts = store_types[\"type\"].value_counts()\n",
    "print(store_counts)\n",
    "\n",
    "# Get the proportion of stores of each type\n",
    "store_props = store_types[\"type\"].value_counts(normalize=True)\n",
    "print(store_props)\n",
    "\n",
    "# Count the number of each department number and sort\n",
    "dept_counts_sorted = store_depts[\"department\"].value_counts(sort=True)\n",
    "print(dept_counts_sorted)\n",
    "\n",
    "# Get the proportion of departments of each number and sort\n",
    "dept_props_sorted = store_depts[\"department\"].value_counts(sort=True, normalize=True)\n",
    "print(dept_props_sorted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "重新分組\n",
    "DataFrame.groupby(by=None, axis=0, level=None, as_index=True, sort=True, group_keys=True, squeeze=<object object>, observed=False, dropna=True)\n",
    "Group DataFrame using a mapper or by a Series of columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9097747 0.0902253 0.       ]\n"
     ]
    }
   ],
   "source": [
    "# 7. What percent of sales occurred at each store type?\n",
    "# Calc total weekly sales\n",
    "sales_all = sales[\"weekly_sales\"].sum()\n",
    "\n",
    "# Subset for type A stores, calc total weekly sales\n",
    "sales_A = sales[sales[\"type\"] == \"A\"][\"weekly_sales\"].sum()\n",
    "\n",
    "# Subset for type B stores, calc total weekly sales\n",
    "sales_B = sales[sales[\"type\"] == \"B\"][\"weekly_sales\"].sum()\n",
    "\n",
    "# Subset for type C stores, calc total weekly sales\n",
    "sales_C = sales[sales[\"type\"] == \"C\"][\"weekly_sales\"].sum()\n",
    "\n",
    "# Get proportion for each type\n",
    "sales_propn_by_type = [sales_A, sales_B, sales_C] / sales_all\n",
    "print(sales_propn_by_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type\n",
      "A    0.909775\n",
      "B    0.090225\n",
      "Name: weekly_sales, dtype: float64\n",
      "type  is_holiday\n",
      "A     False         2.336927e+08\n",
      "      True          2.360181e+04\n",
      "B     False         2.317678e+07\n",
      "      True          1.621410e+03\n",
      "Name: weekly_sales, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# 8. Calculations with .groupby()\n",
    "# Group by type; calc total weekly sales\n",
    "sales_by_type = sales.groupby(\"type\")[\"weekly_sales\"].sum()\n",
    "\n",
    "# Get proportion for each type\n",
    "sales_propn_by_type = sales_by_type / sum(sales_by_type)\n",
    "print(sales_propn_by_type)\n",
    "\n",
    "# From previous step\n",
    "sales_by_type = sales.groupby(\"type\")[\"weekly_sales\"].sum()\n",
    "\n",
    "# Group by type and is_holiday; calc total weekly sales\n",
    "sales_by_type_is_holiday = sales.groupby([\"type\", \"is_holiday\"])[\"weekly_sales\"].sum()\n",
    "print(sales_by_type_is_holiday)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        amin       amax          mean    median\n",
      "type                                           \n",
      "A    -1098.0  293966.05  23674.667242  11943.92\n",
      "B     -798.0  232558.51  25696.678370  13336.08\n",
      "     unemployment                         fuel_price_usd_per_l            \\\n",
      "             amin   amax      mean median                 amin      amax   \n",
      "type                                                                       \n",
      "A           3.879  8.992  7.972611  8.067             0.664129  1.107410   \n",
      "B           7.170  9.765  9.279323  9.199             0.760023  1.107674   \n",
      "\n",
      "                          \n",
      "          mean    median  \n",
      "type                      \n",
      "A     0.744619  0.735455  \n",
      "B     0.805858  0.803348  \n"
     ]
    }
   ],
   "source": [
    "# 9. Multiple grouped summaries\n",
    "\n",
    "# Import numpy with the alias np\n",
    "import numpy as np\n",
    "\n",
    "# For each store type, aggregate weekly_sales: get min, max, mean, and median\n",
    "sales_stats = sales.groupby(\"type\")[\"weekly_sales\"].agg([np.min, np.max, np.mean, np.median])\n",
    "\n",
    "# Print sales_stats\n",
    "print(sales_stats)\n",
    "\n",
    "# For each store type, aggregate unemployment and fuel_price_usd_per_l: get min, max, mean, and median\n",
    "unemp_fuel_stats = sales.groupby(\"type\")[\"unemployment\", \"fuel_price_usd_per_l\"].agg([np.min, np.max, np.mean, np.median])\n",
    "\n",
    "# Print unemp_fuel_stats\n",
    "print(unemp_fuel_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pivot tables\n",
    "DataFrame.pivot_table(values=None, index=None, columns=None, aggfunc='mean', fill_value=None, margins=False, dropna=True, margins_name='All', observed=False)\n",
    "Create a spreadsheet-style pivot table as a DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      weekly_sales\n",
      "type              \n",
      "A     23674.667242\n",
      "B     25696.678370\n",
      "              mean       median\n",
      "      weekly_sales weekly_sales\n",
      "type                           \n",
      "A     23674.667242     11943.92\n",
      "B     25696.678370     13336.08\n",
      "is_holiday         False      True \n",
      "type                               \n",
      "A           23768.583523  590.04525\n",
      "B           25751.980533  810.70500\n"
     ]
    }
   ],
   "source": [
    "# 10. Pivoting on one variable\n",
    "# vThat is, the .pivot_table() method is just an alternative to .groupby()\n",
    "# Pivot for mean weekly_sales for each store type\n",
    "mean_sales_by_type = sales.pivot_table(values=\"weekly_sales\", index=\"type\")\n",
    "\n",
    "# Print mean_sales_by_type\n",
    "print(mean_sales_by_type)\n",
    "\n",
    "# Import NumPy as np\n",
    "import numpy as np\n",
    "\n",
    "# Pivot for mean and median weekly_sales for each store type\n",
    "mean_med_sales_by_type = sales.pivot_table(values=\"weekly_sales\", index=\"type\", aggfunc=[np.mean, np.median])\n",
    "\n",
    "# Print mean_med_sales_by_type\n",
    "print(mean_med_sales_by_type)\n",
    "\n",
    "# Pivot for mean weekly_sales by store type and holiday \n",
    "mean_sales_by_type_holiday = sales.pivot_table(values='weekly_sales', index='type', columns='is_holiday')\n",
    "\n",
    "# Print mean_sales_by_type_holiday\n",
    "print(mean_sales_by_type_holiday)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type                    A              B            All\n",
      "department                                             \n",
      "1            30961.725379   44050.626667   32052.467153\n",
      "2            67600.158788  112958.526667   71380.022778\n",
      "3            17160.002955   30580.655000   18278.390625\n",
      "4            44285.399091   51219.654167   44863.253681\n",
      "5            34821.011364   63236.875000   37189.000000\n",
      "6             7136.292652   10717.297500    7434.709722\n",
      "7            38454.336818   52909.653333   39658.946528\n",
      "8            48583.475303   90733.753333   52095.998472\n",
      "9            30120.449924   66679.301667   33167.020903\n",
      "10           30930.456364   48595.126667   32402.512222\n",
      "11           23028.312727   35488.429167   24066.655764\n",
      "12            6786.840606    9656.520000    7025.980556\n",
      "13           51398.168561   67213.587500   52716.120139\n",
      "14           22457.695303   40400.020000   23952.889028\n",
      "16           25202.751894   29558.182500   25565.704444\n",
      "17           16167.586136   27675.351667   17126.566597\n",
      "18           12201.771212   17361.347500   12631.735903\n",
      "19            1560.951719    3365.895000    1715.661143\n",
      "20            8312.070227   16191.810000    8968.715208\n",
      "21            9324.387197   10368.968333    9411.435625\n",
      "22           14225.324167   26044.797500   15210.280278\n",
      "23           29350.745076   63960.273333   32234.872431\n",
      "24            8204.587576   15376.829167    8802.274375\n",
      "25           13382.164242   20619.285000   13985.257639\n",
      "26           11254.311212   17535.457500   11777.740069\n",
      "27            2079.160455    4553.720833    2285.373819\n",
      "28             968.247348    1422.762500    1006.123611\n",
      "29            6859.108485   14999.843333    7537.503056\n",
      "30            5403.619773   12442.080000    5990.158125\n",
      "31            3221.001818    6151.995000    3465.251250\n",
      "...                   ...            ...            ...\n",
      "54             221.288030     551.016667     248.765417\n",
      "55           15368.005985   20420.726667   15789.066042\n",
      "56            5529.171136     992.310000    5151.099375\n",
      "58            6510.454621    5156.833333    6397.652847\n",
      "59            1358.490530    2536.538333    1456.661181\n",
      "60             461.176591     577.850000     470.899375\n",
      "67           12064.737500   13327.714167   12169.985556\n",
      "71            7486.394318   15945.855000    8191.349375\n",
      "72           72767.860227  145237.726667   78807.015764\n",
      "74           22097.090152   44480.321667   23962.359444\n",
      "77             370.651316    1590.000000     401.916667\n",
      "78               8.893878       1.714286       7.996429\n",
      "79           40643.113106   39802.038333   40573.023542\n",
      "80           22425.941667     116.680000   20566.836528\n",
      "81           28417.831061   11084.591667   26973.394444\n",
      "82           21698.068561   21943.495833   21718.520833\n",
      "83            7020.960985     327.011667    6463.131875\n",
      "85            3593.235379    2887.316667    3534.408819\n",
      "87           22549.672045   21829.132500   22489.627083\n",
      "90           85776.905909   14780.210000   79860.514583\n",
      "91           70423.165227   13199.602500   65654.535000\n",
      "92          139722.204773   50859.278333  132316.960903\n",
      "93           53413.633939    1466.274167   49084.687292\n",
      "94           60081.155303     161.445833   55087.846181\n",
      "95          123933.787121   77082.102500  120029.480069\n",
      "96           21367.042857    9528.538333   20337.607681\n",
      "97           28471.266970    5828.873333   26584.400833\n",
      "98           12875.423182     217.428333   11820.590278\n",
      "99             379.123659       0.000000     379.123659\n",
      "All          23674.667242   25696.678370   23843.950149\n",
      "\n",
      "[81 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# 11. Fill in missing values and sum values with pivot tables\n",
    "# useful arguments, including \n",
    "# fill_value and margins.\n",
    "# Print the mean weekly_sales by department and type; fill missing values with 0s; sum all rows and cols\n",
    "print(sales.pivot_table(values='weekly_sales', index='department', columns='type', fill_value=0, margins=sum))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
